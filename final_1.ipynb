{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcxR-KjgpMxO",
        "outputId": "49f3eb53-aac8-4dd0-a4ec-f4b4ec666877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 10/49 [00:11<00:45,  1.17s/it]\n",
            " 20%|██        | 10/49 [00:09<00:37,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 26s/step - AUC: 0.8583 - loss: 0.4243 - val_AUC: 1.0000 - val_loss: 1.4743\n",
            "Epoch 2/2\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 28s/step - AUC: 1.0000 - loss: 0.0324 - val_AUC: 1.0000 - val_loss: 1.7022\n",
            "Epoch 1/2\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 8s/step - AUC: 0.7018 - loss: 0.7371 - val_AUC: 0.5000 - val_loss: 2.8939\n",
            "Epoch 2/2\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7s/step - AUC: 0.9173 - loss: 0.4623 - val_AUC: 0.5000 - val_loss: 3.0215\n",
            "Epoch 1/2\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 9s/step - AUC: 0.8605 - loss: 0.5445 - val_AUC: 0.6000 - val_loss: 0.7256\n",
            "Epoch 2/2\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 9s/step - AUC: 1.0000 - loss: 0.1369 - val_AUC: 0.5000 - val_loss: 0.7200\n",
            "Epoch 1/2\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - AUC: 0.6482 - loss: 0.7401 - val_AUC: 0.6400 - val_loss: 0.7123\n",
            "Epoch 2/2\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 882ms/step - AUC: 0.9619 - loss: 0.2448 - val_AUC: 0.8100 - val_loss: 0.7062\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 951ms/step\n",
            "Frame-level AUC - Xception: 1.0\n",
            "Frame-level AUC - Patch-ResNet: 0.8527777777777777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a9014c22f20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 7s/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a9014c22f20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4s/step\n",
            "Frame-level AUC - EfficientNetB0: 0.6305555555555555\n",
            "Frame-level Accuracy - EfficientNetB0: 0.47368421052631576\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 517ms/step\n",
            "Frame-level AUC - MesoNet: 0.7805555555555556\n",
            "Frame-level Accuracy - MesoNet: 0.47368421052631576\n",
            "Video-level AUC - Xception: 1.0\n",
            "Video-level AUC - Patch-ResNet: 0.8624999999999999\n",
            "Xception params: 20863529\n",
            "Patch-ResNet params: 230017\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step\n",
            "Xception time: 638.8368606567383 ms\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "Patch-ResNet time: 162.89782524108887 ms\n",
            "EfficientNetB0 params: 4050852\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "EfficientNetB0 time: 221.93288803100586 ms\n",
            "MesoNet params: 75145\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MesoNet time: 120.45764923095703 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# SECTION 1: Setup and Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Flatten, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import Xception, ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import time\n",
        "\n",
        "# Set paths\n",
        "REAL_PATH = '/content/drive/MyDrive/EE656/real'\n",
        "FAKE_PATH = '/content/drive/MyDrive/EE656/fake'\n",
        "\n",
        "# SECTION 2: Frame Extraction and Preprocessing (with Haar face detection)\n",
        "def extract_faces_from_video(video_path, max_frames=10):  # reduced for memory efficiency\n",
        "    faces = []\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "    while cap.isOpened() and frame_count < max_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces_rect = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "        for (x, y, w, h) in faces_rect:\n",
        "            face = frame[y:y+h, x:x+w]\n",
        "            face = cv2.resize(face, (299, 299))\n",
        "            faces.append(face)\n",
        "            break  # only one face per frame\n",
        "        frame_count += 1\n",
        "    cap.release()\n",
        "    return faces\n",
        "\n",
        "# Load real and fake frames (limit dataset size for memory)\n",
        "def load_dataset(max_videos_per_class=10):\n",
        "    X, y, vids = [], [], []\n",
        "    for label, folder in enumerate([REAL_PATH, FAKE_PATH]):\n",
        "        for i, filename in enumerate(tqdm(os.listdir(folder))):\n",
        "            if filename.endswith('.mp4'):\n",
        "                if i >= max_videos_per_class:\n",
        "                    break\n",
        "                video_path = os.path.join(folder, filename)\n",
        "                faces = extract_faces_from_video(video_path)\n",
        "                for face in faces:\n",
        "                    X.append(face / 255.0)\n",
        "                    y.append(label)\n",
        "                    vids.append(filename)\n",
        "    return np.array(X), np.array(y), np.array(vids)\n",
        "\n",
        "X, y, vids = load_dataset()\n",
        "\n",
        "# SECTION 3: Train/Test Split\n",
        "X_train, X_test, y_train, y_test, vids_train, vids_test = train_test_split(X, y, vids, test_size=0.2, stratify=y, random_state=42)\n",
        "#Resize for MesoNet\n",
        "X_train_m = np.array([cv2.resize((img*255).astype(np.uint8), (256,256))/255.0 for img in X_train])\n",
        "X_test_m  = np.array([cv2.resize((img*255).astype(np.uint8), (256,256))/255.0 for img in X_test])\n",
        "\n",
        "# SECTION 4: Build Models\n",
        "# Xception\n",
        "inp = Input(shape=(299, 299, 3))\n",
        "xception = Xception(include_top=False, weights='imagenet', input_tensor=inp)\n",
        "x = GlobalAveragePooling2D()(xception.output)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model_x = Model(inputs=inp, outputs=x)\n",
        "model_x.compile(optimizer=Adam(learning_rate=2e-4), loss='binary_crossentropy', metrics=['AUC'])\n",
        "\n",
        "# Patch-ResNet (Layer1)\n",
        "inp2 = Input(shape=(299, 299, 3))\n",
        "resnet = ResNet50(include_top=False, weights='imagenet', input_tensor=inp2)\n",
        "res_layer1 = resnet.get_layer('conv2_block3_out').output\n",
        "y = GlobalAveragePooling2D()(res_layer1)\n",
        "y = Dense(1, activation='sigmoid')(y)\n",
        "model_r = Model(inputs=inp2, outputs=y)\n",
        "model_r.compile(optimizer=Adam(learning_rate=2e-4), loss='binary_crossentropy', metrics=['AUC'])\n",
        "\n",
        "# --- EfficientNetB0 ---\n",
        "inp3 = Input(shape=(299, 299, 3))\n",
        "effnet = EfficientNetB0(include_top=False, weights='imagenet', input_tensor=inp3)\n",
        "e = GlobalAveragePooling2D()(effnet.output)\n",
        "e = Dense(1, activation='sigmoid')(e)\n",
        "model_e = Model(inputs=inp3, outputs=e)\n",
        "model_e.compile(optimizer=Adam(learning_rate=2e-4),\n",
        "                loss='binary_crossentropy', metrics=['AUC'])\n",
        "\n",
        "# --- MesoNet (256×256 input) ---\n",
        "def build_mesonet(input_shape=(256,256,3)):\n",
        "    m = Sequential()\n",
        "    m.add(Conv2D(8, (3, 3), padding='same', input_shape=input_shape))\n",
        "    m.add(BatchNormalization()); m.add(Activation('relu'))\n",
        "    m.add(Conv2D(8, (5, 5), strides=2, padding='same'))\n",
        "    m.add(BatchNormalization()); m.add(Activation('relu'))\n",
        "    m.add(Conv2D(16, (3, 3), padding='same'))\n",
        "    m.add(BatchNormalization()); m.add(Activation('relu'))\n",
        "    m.add(Conv2D(16, (5, 5), strides=2, padding='same'))\n",
        "    m.add(BatchNormalization()); m.add(Activation('relu'))\n",
        "    m.add(Flatten())\n",
        "    m.add(Dropout(0.5))\n",
        "    m.add(Dense(1, activation='sigmoid'))\n",
        "    m.compile(optimizer=Adam(learning_rate=2e-4),\n",
        "              loss='binary_crossentropy', metrics=['AUC'])\n",
        "    return m\n",
        "\n",
        "# Instantiate MesoNet\n",
        "model_meso = build_mesonet()\n",
        "\n",
        "# SECTION 5: Training (reduce batch size and epochs)\n",
        "model_x.fit(X_train, y_train, epochs=2, batch_size=16, validation_split=0.1)\n",
        "model_r.fit(X_train, y_train, epochs=2, batch_size=16, validation_split=0.1)\n",
        "model_e.fit(X_train,   y_train, epochs=2, batch_size=16, validation_split=0.1)\n",
        "model_meso.fit(X_train_m, y_train, epochs=2, batch_size=16, validation_split=0.1)\n",
        "\n",
        "# SECTION 6: Evaluation\n",
        "pred_x = model_x.predict(X_test)\n",
        "pred_r = model_r.predict(X_test)\n",
        "auc_frame_x = roc_auc_score(y_test, pred_x)\n",
        "auc_frame_r = roc_auc_score(y_test, pred_r)\n",
        "print(\"Frame-level AUC - Xception:\", auc_frame_x)\n",
        "print(\"Frame-level AUC - Patch-ResNet:\", auc_frame_r)\n",
        "# SECTION 6.1: Evaluate EfficientNetB0\n",
        "pred_e = model_e.predict(X_test).flatten()\n",
        "auc_e = roc_auc_score(y_test, pred_e)\n",
        "acc_e = accuracy_score(y_test, (pred_e>0.5).astype(int))\n",
        "print(\"Frame-level AUC - EfficientNetB0:\", auc_e)\n",
        "print(\"Frame-level Accuracy - EfficientNetB0:\", acc_e)\n",
        "\n",
        "# SECTION 6.2: Evaluate MesoNet\n",
        "pred_meso = model_meso.predict(X_test_m).flatten()\n",
        "auc_m = roc_auc_score(y_test, pred_meso)\n",
        "acc_m = accuracy_score(y_test, (pred_meso>0.5).astype(int))\n",
        "print(\"Frame-level AUC - MesoNet:\", auc_m)\n",
        "print(\"Frame-level Accuracy - MesoNet:\", acc_m)\n",
        "\n",
        "# Video-level AUC\n",
        "video_df = pd.DataFrame({\n",
        "    'video': vids_test,\n",
        "    'label': y_test,\n",
        "    'pred_x': pred_x.flatten(),\n",
        "    'pred_r': pred_r.flatten()\n",
        "})\n",
        "vid_preds_x = video_df.groupby('video')['pred_x'].mean()\n",
        "vid_labels = video_df.groupby('video')['label'].first()\n",
        "vid_preds_r = video_df.groupby('video')['pred_r'].mean()\n",
        "auc_vid_x = roc_auc_score(vid_labels, vid_preds_x)\n",
        "auc_vid_r = roc_auc_score(vid_labels, vid_preds_r)\n",
        "print(\"Video-level AUC - Xception:\", auc_vid_x)\n",
        "print(\"Video-level AUC - Patch-ResNet:\", auc_vid_r)\n",
        "\n",
        "# SECTION 7: Params and Inference Time\n",
        "print(\"Xception params:\", model_x.count_params())\n",
        "print(\"Patch-ResNet params:\", model_r.count_params())\n",
        "\n",
        "start = time.time()\n",
        "_ = model_x.predict(np.expand_dims(X_test[0], axis=0))\n",
        "print(\"Xception time:\", (time.time() - start) * 1000, \"ms\")\n",
        "\n",
        "start = time.time()\n",
        "_ = model_r.predict(np.expand_dims(X_test[0], axis=0))\n",
        "print(\"Patch-ResNet time:\", (time.time() - start) * 1000, \"ms\")\n",
        "\n",
        "# SECTION 7.1: Params & Inference Time\n",
        "print(\"EfficientNetB0 params:\", model_e.count_params())\n",
        "start = time.time(); _ = model_e.predict(np.expand_dims(X_test[0],axis=0))\n",
        "print(\"EfficientNetB0 time:\", (time.time()-start)*1000, \"ms\")\n",
        "\n",
        "print(\"MesoNet params:\", model_meso.count_params())\n",
        "start = time.time(); _ = model_meso.predict(np.expand_dims(X_test_m[0],axis=0))\n",
        "print(\"MesoNet time:\", (time.time()-start)*1000, \"ms\")\n",
        "\n",
        "# SECTION 8: Save Model and Results\n",
        "model_x.save('/content/drive/MyDrive/xception_model.h5')\n",
        "model_r.save('/content/drive/MyDrive/patchresnet_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bS-LS2hw2fz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}